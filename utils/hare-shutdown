#!/usr/bin/env python3

# :help: stop the cluster

import logging
import os
import re
import threading

from socket import gethostname
from typing import Dict, List, NamedTuple
from queue import Queue
from consul import Consul

Process = NamedTuple('Process', [('node', str), ('consul_name', str),
                                 ('systemd_name', str), ('fidk', int),
                                 ('status', str)])
shutdown_sequence = ('s3service', 'ios', 'confd', 'hax', 'consul')


def _setup_logging():
    logging.basicConfig(level=logging.INFO, format='%(message)s')


def processfid2str(fidk: int) -> str:
    return '{:#x}:{:#x}'.format(ord('r') << 56 | 1, fidk)


def get_kv(cns: Consul, key: str) -> str:
    kv: Dict[str, bytes] = cns.kv.get(key)[1]
    return kv['Value'].decode() if kv and kv['Value'] is not None else ''


def get_systemd_name(fidk: int, svc_name: str) -> str:
    if svc_name == 'hax':
        return 'hare-hax'
    elif svc_name == 's3service':
        return 's3server@' + processfid2str(fidk)
    else:
        return 'm0d@' + processfid2str(fidk)


def processes_by_consul_svc_name(cns: Consul) -> Dict[str, List[Process]]:
    """Processes grouped by Consul service name.
    """
    processes: Dict[str, List[Process]] = {}
    for node in cns.catalog.nodes()[1]:
        for svc in cns.health.node(node['Node'])[1]:
            svc_name = svc['ServiceName']
            if svc_name:
                fidk = int(svc['ServiceID'])
                processes.setdefault(svc_name, []).append(
                    Process(node=node['Node'],
                            consul_name=svc_name,
                            systemd_name=get_systemd_name(fidk, svc_name),
                            fidk=fidk,
                            status=svc['Status']))
        consul_status = 'passing' if consul_is_active_at(node['Node']) \
            else 'offline'
        processes.setdefault('consul', []).append(
            Process(node=node['Node'],
                    consul_name='consul',
                    systemd_name='hare-consul-agent',
                    fidk=0,
                    status=consul_status))
    return processes


def is_localhost(hostname: str) -> bool:
    name = gethostname()
    return hostname in ('localhost', '127.0.0.1', name, f'{name}.local')


def is_fake_leader_name(leader: str) -> bool:
    return re.match(r'^elect[0-9]+$', leader) is not None


def ssh_prefix(hostname: str) -> str:
    assert hostname
    return '' if is_localhost(hostname) else f'ssh {hostname} '


def consul_is_active_at(hostname: str) -> bool:
    cmd = ssh_prefix(hostname) + \
        'sudo systemctl is-active --quiet hare-consul-agent'
    return os.system(cmd) == 0


def pcs_consul_is_active_at(hostname: str) -> bool:
    cmd = ssh_prefix(hostname) + \
        'sudo systemctl is-active --quiet hare-consul-agent*'
    return os.system(cmd) == 0


def exec_silent(cmd: str) -> bool:
    return os.system(cmd) == 0


def exec(cmd: str) -> None:
    assert cmd
    print('done' if exec_silent(cmd) else '**ERROR**')


def process_stop(proc: Process) -> None:
    if proc.status != 'passing':
        return
    label = f' ({proc.consul_name})' if proc.systemd_name.startswith('m0d@') \
        else ''
    logging.info(f'Stopping {proc.systemd_name}{label} at {proc.node}... ')
    ok = exec_silent('{}sudo systemctl stop --force {}'.format(
        ssh_prefix(proc.node), proc.systemd_name))
    if ok:
        logging.info(f'Stopped {proc.systemd_name}{label} at {proc.node}')
    else:
        logging.error(f'**ERROR** Failed to stop {proc.systemd_name}{label}'
                      f' at {proc.node}')


class StopProcess:
    def __init__(self, process: Process):
        self.process = process


class QuitMessage:
    pass


class Worker(threading.Thread):
    def __init__(self, queue: Queue):
        super().__init__(target=self._do_work,
                         args=(queue, ))

    def _do_work(self, queue):
        logging.debug('Started thread')
        while True:
            msg = queue.get()
            if isinstance(msg, StopProcess):
                process_stop(msg.process)
            if isinstance(msg, QuitMessage):
                logging.debug('Exiting thread')
                return


def _stop_parallel(process_list: List[Process], thread_count: int = 8) -> None:
    size = len(process_list)

    if not size:
        return
    q: Queue = Queue(maxsize=size)
    thread_count = min(thread_count, size)

    worker_pool: List[Worker] = [Worker(q) for i in range(thread_count)]

    for w in worker_pool:
        w.start()

    for proc in process_list:
        q.put(StopProcess(process=proc))
    for i in range(thread_count):
        q.put(QuitMessage())

    for worker in worker_pool:
        worker.join()


def main() -> None:
    _setup_logging()
    if not consul_is_active_at('localhost'):
        if pcs_consul_is_active_at('localhost'):
            exit("Cluster is run by Pacemaker, try `pcs cluster stop --all'")
        else:
            exit('Cluster is not running')

    cns = Consul()
    processes = processes_by_consul_svc_name(cns)
    leader_node = get_kv(cns, 'leader')

    for svc in shutdown_sequence:
        # Some processes may be not started as per configuration
        if svc in processes:
            _stop_parallel([proc for proc in processes[svc]])

    if leader_node and not is_fake_leader_name(leader_node):
        print(f'Killing RC Leader at {leader_node}... ', end='', flush=True)
        exec(ssh_prefix(leader_node) + 'sudo pkill --exact -KILL consul')


if __name__ == '__main__':
    main()
